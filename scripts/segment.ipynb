{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams['font.size'] = 10\n",
    "rcParams['font.family'] = 'serif'\n",
    "rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from canon.pattern.model import GMModel, KMeansModel, BGMModel, MeanShiftModel\n",
    "from canon.seq.seqreader import SeqReader\n",
    "from canon.pattern.labeler import SeqLabeler\n",
    "\n",
    "def read_seq(seq, key=\"orsnr___\"):\n",
    "    seqfile = os.path.join(\"seq\", seq+\".SEQ\")\n",
    "    reader = SeqReader(seqfile)    \n",
    "    Z = reader.get_Zmap(key)[0]\n",
    "    return Z[::-1, :]\n",
    "\n",
    "def fill_features(features, img_shape):\n",
    "    num_points = np.prod(img_shape)\n",
    "    if len(features) != num_points:\n",
    "        print(\"Filling %d features to %d data points\" % (len(features), num_points))\n",
    "        features2 = np.zeros((np.prod(img_shape), features.shape[1] - 1))\n",
    "        features2[features[:, 0].astype('int') - 1] = features[:, 1:]\n",
    "        return features2\n",
    "    else:\n",
    "        return features[:, 1:]\n",
    "    \n",
    "def xy_to_idx(x, y, img_shape):\n",
    "    return y * img_shape[1] + x\n",
    "\n",
    "def idx_to_xy(idx, img_shape, flip_vertical=True):\n",
    "    x = int(idx / img_shape[1])\n",
    "    y = idx % img_shape[1]\n",
    "    if flip_vertical:\n",
    "        x = img_shape[0] - x - 1\n",
    "    return y, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_file = \"hit_100_20_3_1_150_150\"\n",
    "# img_shape = (150, 150)\n",
    "# aspect_ratio = 1\n",
    "# seqs = [\"hit_100_20_3_1_150_150\"]\n",
    "\n",
    "# feature_file = \"au29_area2_50_150_128\"\n",
    "# img_shape = (50, 150)\n",
    "# aspect_ratio = 1.5\n",
    "\n",
    "feature_file = \"BTO_25C_wb3_60_100\"\n",
    "img_shape = (60, 100)\n",
    "aspect_ratio = 1\n",
    "seqs = [\"BTO_25C_wb3_\"]\n",
    "\n",
    "# feature_file=\"C5_30x30\"\n",
    "# img_shape = (30, 30)\n",
    "# aspect_ratio = 1\n",
    "# seqs = [\"C5_30x30\"]\n",
    "\n",
    "ae_models = []\n",
    "features = []\n",
    "\n",
    "with h5py.File(os.path.join(\"features\", feature_file +'.hdf5'), 'r') as h5f:\n",
    "    for k in h5f.keys():\n",
    "        print(k)\n",
    "        data = np.array(h5f.get(k))\n",
    "        print(data.shape)\n",
    "        features.append(fill_features(data, img_shape))\n",
    "        ae_models.append(k)\n",
    "print(\"Read {} datasets for models {}\".format(len(features), ae_models))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct Coloring\n",
    "Directly color each point using the first 3 principal components, without clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_direct_color(features, ax):\n",
    "    pca = PCA(n_components=3)\n",
    "    X = pca.fit_transform(features)\n",
    "    pca_range = [X.min(axis=0), X.max(axis=0)]\n",
    "    X = (X - pca_range[0]) / (pca_range[1] - pca_range[0])\n",
    "    Z = np.zeros((img_shape[0], img_shape[1], 3))\n",
    "    Z[:, :, 0] = X[:, 0].reshape(img_shape)\n",
    "    Z[:, :, 1] = X[:, 1].reshape(img_shape)\n",
    "    Z[:, :, 2] = X[:, 2].reshape(img_shape)\n",
    "    ax.imshow(Z[::-1, :, :], aspect=aspect_ratio)\n",
    "\n",
    "for i, m in enumerate(ae_models):\n",
    "    fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(6, 5))\n",
    "    f = features[i]\n",
    "    draw_direct_color(f, ax)\n",
    "    ax.set_title(\"[%d] %s\" % (i, m), fontsize=12)\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick one data set for following calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 0\n",
    "ae_model = ae_models[dataset]\n",
    "samples = features[dataset]\n",
    "\n",
    "N = samples.shape[0]\n",
    "M = samples.shape[1]\n",
    "\n",
    "mPCA = None\n",
    "\n",
    "model = KMeansModel()\n",
    "if mPCA is not None and mPCA < samples.shape[1]:\n",
    "    pca = PCA(n_components=mPCA)\n",
    "    preprocessors = [pca]\n",
    "else:\n",
    "    preprocessors=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "The normal clustering + labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 64\n",
    "\n",
    "if N > 6400:\n",
    "    print(\"To many feature vectors, pick 6400 samples to train clustering\")\n",
    "    training_set = samples[np.random.choice(np.arange(N), 6400)]\n",
    "else:\n",
    "    training_set = samples\n",
    "model.train(training_set, n_clusters=K, preprocessors=preprocessors)\n",
    "\n",
    "scores = np.array(model.score(samples))\n",
    "\n",
    "silhouette = model.compute_silhouette_score(samples)\n",
    "calinski = model.compute_calinski_harabaz_score(samples)\n",
    "print(\"Silhouette Score = {}, Calinski-Harabaz Score = {}\".format(silhouette, calinski))\n",
    "\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1)\n",
    "\n",
    "Z = model.color_by_pca(scores.reshape(img_shape), scaling='centroids')\n",
    "ax.imshow(Z[::-1, :, :], aspect=aspect_ratio)\n",
    "ax.set_title(r'%s: $m_{\\rm PCA}$=%s, $K$=%s' % (ae_model, mPCA, K));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing Labeler\n",
    "\n",
    "Requires SEQ file(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = read_seq(seqs[0])\n",
    "vmax, vmin = Z.max(), Z.min()\n",
    "seqfiles = [os.path.join(\"seq\", seq+\".SEQ\") for seq in seqs]\n",
    "labler = SeqLabeler(seqfiles)\n",
    "Z_seq = labler.Z_map()\n",
    "mask = np.where(np.isfinite(Z_seq))\n",
    "\n",
    "Z = model.score_by_seqs(samples, seqfiles)\n",
    "fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(12, 5))\n",
    "ax[0].imshow(Z[::-1, :], cmap='jet', aspect=1)\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title(r'$K$=%d' % K, fontsize=12)\n",
    "ax[1].imshow(Z_seq[::-1, :], cmap='jet', aspect=1)\n",
    "ax[1].axis('off')\n",
    "ax[1].set_title(r'True Value (SEQ)', fontsize=12)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silhouette Score & Calinski-Harabaz Score\n",
    "Use Silhouette Score & Calinski-Harabaz Score to estimate number of \"coarse\" clusters.\n",
    "Good for grain boundaries and phase boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "Ks = np.arange(2, 20, 1)\n",
    "SCs=[]\n",
    "\n",
    "def sc_scores(K):\n",
    "    print(\"K=\", K)\n",
    "    model = KMeansModel()\n",
    "    pca = PCA(n_components=32)\n",
    "    if N > 6400:\n",
    "        print(\"To many feature vectors, pick 6400 samples to train clustering\")\n",
    "        training_set = samples[np.random.choice(np.arange(N), 6400)]\n",
    "    else:\n",
    "        training_set = samples\n",
    "    model.train(training_set, n_clusters=K, preprocessors=preprocessors)\n",
    "    silhouette = model.compute_silhouette_score(samples)\n",
    "    calinski = model.compute_calinski_harabaz_score(samples)\n",
    "    print(\"Silhouette Score = {}, Calinski-Harabaz Score = {}\".format(silhouette, calinski))\n",
    "    return silhouette, calinski\n",
    "\n",
    "with Parallel(n_jobs=-1, verbose=1) as parallel:\n",
    "    SCs = parallel(delayed(sc_scores)(k) for k in Ks)\n",
    "    SCs = np.array(SCs)\n",
    "    \n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "ax[0].plot(Ks, SCs[:, 0], 'o--k', markerfacecolor='w', markersize=5)\n",
    "ax[0].set_xlabel(r'Number of Clusters', fontsize=12)\n",
    "ax[0].set_ylabel(r'Silhouette Score', fontsize=12)\n",
    "\n",
    "ax[1].plot(Ks, SCs[:, 1], 'o--k', markerfacecolor='w', markersize=5)\n",
    "ax[1].set_xlabel(r'Number of Clusters', fontsize=12)\n",
    "ax[1].set_ylabel(r'Calinski-Harabaz Score', fontsize=12)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
